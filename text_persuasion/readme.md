
Text Persuasion Strategy Dataset. To use, cite : 

```
1. 
@inproceedings{bhattacharyya-etal-2023-video,
    title = "A Video Is Worth 4096 Tokens: Verbalize Videos To Understand Them In Zero Shot",
    author = "Bhattacharyya, Aanisha  and
      Singla, Yaman K  and
      Krishnamurthy, Balaji  and
      Shah, Rajiv Ratn  and
      Chen, Changyou",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.608",
    doi = "10.18653/v1/2023.emnlp-main.608",
    pages = "9822--9839",
    abstract = "Multimedia content, such as advertisements and story videos, exhibit a rich blend of creativity and multiple modalities. They incorporate elements like text, visuals, audio, and storytelling techniques, employing devices like emotions, symbolism, and slogans to convey meaning. There is a dearth of large annotated training datasets in the multimedia domain hindering the development of supervised learning models with satisfactory performance for real-world applications. On the other hand, the rise of large language models (LLMs) has witnessed remarkable zero-shot performance in various natural language processing (NLP) tasks, such as emotion classification, question answering, and topic classification. To leverage such advanced techniques to bridge this performance gap in multimedia understanding, we propose verbalizing long videos to generate their descriptions in natural language, followed by performing video-understanding tasks on the generated story as opposed to the original video. Through extensive experiments on fifteen video-understanding tasks, we demonstrate that our method, despite being zero-shot, achieves significantly better results than supervised baselines for video understanding. Furthermore, to alleviate a lack of story understanding benchmarks, we publicly release the first dataset on a crucial task in computational social science on persuasion strategy identification.",
}

2. 

@article{Kumar_Jha_Gupta_Aggarwal_Garg_Malyan_Bhardwaj_Ratn Shah_Krishnamurthy_Chen_2023, title={Persuasion Strategies in Advertisements}, volume={37}, url={https://ojs.aaai.org/index.php/AAAI/article/view/25076}, DOI={10.1609/aaai.v37i1.25076}, abstractNote={Modeling what makes an advertisement persuasive, i.e., eliciting the desired response from consumer, is critical to the
study of propaganda, social psychology, and marketing. Despite its importance, computational modeling of persuasion
in computer vision is still in its infancy, primarily due to
the lack of benchmark datasets that can provide persuasion-strategy labels associated with ads. Motivated by persuasion literature in social psychology and marketing, we introduce an extensive vocabulary of persuasion strategies and
build the first ad image corpus annotated with persuasion
strategies. We then formulate the task of persuasion strategy prediction with multi-modal learning, where we design
a multi-task attention fusion model that can leverage other
ad-understanding tasks to predict persuasion strategies. The
dataset also provides image segmentation masks, which labels persuasion strategies in the corresponding ad images on
the test split. We publicly release our code and dataset at https://midas-research.github.io/persuasion-advertisements/.}, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Kumar, Yaman and Jha, Rajat and Gupta, Arunim and Aggarwal, Milan and Garg, Aditya and Malyan, Tushar and Bhardwaj, Ayush and Ratn Shah, Rajiv and Krishnamurthy, Balaji and Chen, Changyou}, year={2023}, month={Jun.}, pages={57-66} }

```
